{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFDC6TgLorsU"
      },
      "source": [
        "# EdgeNeXt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d42Oq6eHKPI1",
        "outputId": "3499bb57-136d-403c-e223-398ccfe4e914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/elmadafri/the-wildfire-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.94G/9.94G [01:41<00:00, 105MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/elmadafri/the-wildfire-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"elmadafri/the-wildfire-dataset/versions/1\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzQjfZJClO98"
      },
      "outputs": [],
      "source": [
        "!rm /root/.cache/kagglehub/datasets/elmadafri/the-wildfire-dataset/versions/1/the_wildfire_dataset/the_wildfire_dataset/val/fire/Both_smoke_and_fire/desktop.ini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKNpK6JhorsV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from timm import create_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdDPqeWcveKM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomFireDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.binary_labels = []\n",
        "        self.multi_class_labels = []\n",
        "\n",
        "        # Define mappings for binary and multi-class labels\n",
        "        binary_label_mapping = {'fire': 1, 'nofire': 0}\n",
        "        multi_class_mapping = {\n",
        "            'fire': {'Both_smoke_and_fire': 0, 'Smoke_from_fires': 1},\n",
        "            'nofire': {'Fire_confounding_elements': 2, 'Forested_areas_without_confounding_elements': 3, 'Smoke_confounding_elements': 4}\n",
        "        }\n",
        "\n",
        "        # Traverse the root directory and collect image paths and labels\n",
        "        for binary_label_name in os.listdir(root_dir):\n",
        "            binary_label_path = os.path.join(root_dir, binary_label_name)\n",
        "            if os.path.isdir(binary_label_path):\n",
        "                # Assign binary label\n",
        "                binary_label = binary_label_mapping[binary_label_name]\n",
        "\n",
        "                # Traverse subclasses\n",
        "                for subclass_name in os.listdir(binary_label_path):\n",
        "                    subclass_path = os.path.join(binary_label_path, subclass_name)\n",
        "                    if os.path.isdir(subclass_path):\n",
        "                        # Assign multi-class label\n",
        "                        multi_class_label = multi_class_mapping[binary_label_name][subclass_name]\n",
        "\n",
        "                        # Collect all images in the subclass directory\n",
        "                        for img_name in os.listdir(subclass_path):\n",
        "                            img_path = os.path.join(subclass_path, img_name)\n",
        "                            if os.path.isfile(img_path):\n",
        "                                self.image_paths.append(img_path)\n",
        "                                self.binary_labels.append(binary_label)\n",
        "                                self.multi_class_labels.append(multi_class_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        binary_label = self.binary_labels[idx]\n",
        "        multi_class_label = self.multi_class_labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, (torch.tensor(binary_label, dtype=torch.float), torch.tensor(multi_class_label, dtype=torch.long))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgewvZivs_sb"
      },
      "outputs": [],
      "source": [
        "# Define transformations for the test set\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load your test dataset\n",
        "test_dataset = CustomFireDataset(root_dir=\"/root/.cache/kagglehub/datasets/elmadafri/the-wildfire-dataset/versions/1/the_wildfire_dataset/the_wildfire_dataset/test\", transform=test_transforms)\n",
        "\n",
        "# Create a DataLoader for the test dataset\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52VSqbJBorsW"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from transformers import MobileViTForImageClassification, MobileViTImageProcessor"
      ],
      "metadata": {
        "id": "vBUhxg1R4hPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use pretrained weights\n",
        "model = MobileViTForImageClassification.from_pretrained(\"apple/mobilevit-small\")\n",
        "\n",
        "# Fire vs No Fire\n",
        "in_features = model.classifier.in_features\n",
        "\n",
        "# Strip out original classifier\n",
        "model.classifier = nn.Identity()\n",
        "\n",
        "# Binary Head\n",
        "binary_head = nn.Sequential(\n",
        "    nn.Linear(in_features, 1),\n",
        "    nn.Sigmoid()\n",
        ")\n",
        "\n",
        "# Multi-class Head -> 5 output classes\n",
        "multi_class_head = nn.Linear(in_features, 5)"
      ],
      "metadata": {
        "id": "sPOPKzrd4fNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(model)"
      ],
      "metadata": {
        "id": "JI5-DuqTrKi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"mobileVit_fire_multi_classifier_Variant_A.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2O2qbGStiKw",
        "outputId": "a28b5799-ed05-453f-bf78-f7d961753c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-50fb076fdb3b>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"mobileVit_fire_multi_classifier_Variant_A.pth\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "model.eval()\n",
        "#binary_head.eval()\n",
        "#multi_class_head.eval()\n",
        "\n",
        "quantized_model = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Quantize the binary head (IGNORE - ONLY QUANTIZE BACKBONE)\n",
        "#binary_head = quantize_dynamic(binary_head, {nn.Linear}, dtype=torch.qint8)\n",
        "\n",
        "# Quantize the multi-class head (IGNORE - ONLY QUANTIZE BACKBONE)\n",
        "#multi_class_head = quantize_dynamic(multi_class_head, {nn.Linear}, dtype=torch.qint8)"
      ],
      "metadata": {
        "id": "gmEMm_MztCQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcsqOo-xudHK"
      },
      "source": [
        "## Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ibrtd8M6WE80",
        "outputId": "996c83f2-b799-4006-fda2-4ce7e99ae4ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Ensure quantized_model, binary_head, and multi_class_head are defined and loaded\n",
        "# Make sure binary_head and multi_class_head are also on the CPU if you moved quantized_model to CPU\n",
        "binary_head = binary_head.to('cpu')\n",
        "multi_class_head = multi_class_head.to('cpu')\n",
        "\n",
        "device = torch.device('cpu')\n",
        "quantized_model = quantized_model.to(device)\n",
        "quantized_model.eval()\n",
        "binary_head.eval()\n",
        "multi_class_head.eval()\n",
        "\n",
        "# Initialize lists to store results\n",
        "true_binary_labels = []\n",
        "predicted_binary_probs = []  # Probabilities for the positive class (fire)\n",
        "\n",
        "true_multi_class_labels = []\n",
        "predicted_multi_class_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, (binary_labels, multi_class_labels) in test_loader:\n",
        "        images = images.to(device)\n",
        "        binary_labels = binary_labels.to(device)\n",
        "        multi_class_labels = multi_class_labels.to(device)\n",
        "\n",
        "        # quantized_model returns ImageClassifierOutputWithNoAttention\n",
        "        outputs = quantized_model(images)  # This is not a Tensor, but an output object.\n",
        "\n",
        "        # Extract the logits as the features tensor\n",
        "        features = outputs.logits  # logits is a Tensor\n",
        "\n",
        "        # Now pass features to your heads (which are quantized linear layers expecting Tensors)\n",
        "        binary_output = binary_head(features)\n",
        "        multi_class_output = multi_class_head(features)\n",
        "\n",
        "        # Convert binary logits to probabilities\n",
        "        binary_probs = torch.sigmoid(binary_output).squeeze().cpu().numpy()\n",
        "\n",
        "        # Get predicted class labels for multi-class classification\n",
        "        _, predicted_multi_class = torch.max(multi_class_output, 1)\n",
        "        predicted_multi_class = predicted_multi_class.cpu().numpy()\n",
        "\n",
        "        # Store true labels and predictions as before\n",
        "        true_binary_labels.extend(binary_labels.cpu().numpy())\n",
        "        predicted_binary_probs.extend(binary_probs)\n",
        "        true_multi_class_labels.extend(multi_class_labels.cpu().numpy())\n",
        "        predicted_multi_class_labels.extend(predicted_multi_class)\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "results = pd.DataFrame({\n",
        "    \"True Binary Labels\": true_binary_labels,\n",
        "    \"Predicted Binary Probabilities\": predicted_binary_probs,\n",
        "    \"True Multi-Class Labels\": true_multi_class_labels,\n",
        "    \"Predicted Multi-Class Labels\": predicted_multi_class_labels\n",
        "})\n",
        "\n",
        "# Save results to CSV\n",
        "results.to_csv(\"quantized_mobilevit_test_results.csv\", index=False)\n",
        "#print(\"Test results saved to 'quantized_mobilevit_test_results.csv'.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(quantized_model.state_dict(), \"mobilevit_quantized_model.pth\")"
      ],
      "metadata": {
        "id": "Xhh7nTvHi7Qd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time  # For measuring time\n",
        "import pandas as pd  # For saving to CSV\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device('cpu')\n",
        "model = model.to(device)\n",
        "binary_head = binary_head.to(device)\n",
        "\n",
        "model.eval()\n",
        "binary_head.eval()\n",
        "\n",
        "prediction_times = []\n",
        "true_binary_labels = []\n",
        "predicted_binary_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, (binary_labels, _) in test_loader:\n",
        "        images = images.to(device)\n",
        "        binary_labels = binary_labels.to(device)\n",
        "\n",
        "        # Start timing the prediction\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Forward pass through the non-quantized model to get features\n",
        "        outputs = model(images)\n",
        "        features = outputs.logits\n",
        "\n",
        "        # Forward pass through binary head\n",
        "        binary_output = binary_head(features)\n",
        "\n",
        "        # End timing the prediction\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate the time taken for this prediction\n",
        "        prediction_time = end_time - start_time\n",
        "        prediction_times.append(prediction_time)\n",
        "\n",
        "        # Convert binary logits to probabilities (already in sigmoid form from head)\n",
        "        binary_probs = binary_output.squeeze().cpu().numpy()\n",
        "\n",
        "        # Store the results\n",
        "        true_binary_labels.extend(binary_labels.cpu().numpy())\n",
        "        predicted_binary_probs.extend(binary_probs)\n",
        "\n",
        "# Combine all data into a DataFrame\n",
        "data = pd.DataFrame({\n",
        "    \"Prediction Times (seconds)\": prediction_times\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "data.to_csv(\"cpu_mobilevit_prediction_time.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVFZPxWy2Yx0",
        "outputId": "933d67d1-5ae8-40e6-f809-baf8e8016286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time  # For measuring time\n",
        "import pandas as pd  # For saving to CSV\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Ensure quantized_model and binary_head are defined and loaded\n",
        "# and that they are on the CPU\n",
        "binary_head = binary_head.to('cpu')\n",
        "quantized_model = quantized_model.to('cpu')\n",
        "\n",
        "quantized_model.eval()\n",
        "binary_head.eval()\n",
        "\n",
        "device = torch.device('cpu')\n",
        "\n",
        "# Lists to store results\n",
        "prediction_times = []\n",
        "true_binary_labels = []\n",
        "predicted_binary_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, (binary_labels, _) in test_loader:\n",
        "        images = images.to(device)\n",
        "        binary_labels = binary_labels.to(device)\n",
        "\n",
        "        # Start timing the prediction\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Forward pass through the quantized model to get an output object\n",
        "        outputs = quantized_model(images)\n",
        "        features = outputs.logits\n",
        "\n",
        "        # Pass features through the binary head\n",
        "        binary_output = binary_head(features)\n",
        "\n",
        "        # End timing the prediction\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate and store the time taken for this prediction\n",
        "        prediction_time = end_time - start_time\n",
        "        prediction_times.append(prediction_time)\n",
        "\n",
        "        # Convert binary logits to probabilities\n",
        "        binary_probs = torch.sigmoid(binary_output).squeeze().cpu().numpy()\n",
        "\n",
        "        # Store true labels and predictions for binary classification\n",
        "        true_binary_labels.extend(binary_labels.cpu().numpy())\n",
        "        predicted_binary_probs.extend(binary_probs)\n",
        "\n",
        "# Combine all data into a single DataFrame\n",
        "data = pd.DataFrame({\n",
        "    \"Prediction Times (seconds)\": prediction_times\n",
        "})\n",
        "\n",
        "# Save results to CSV\n",
        "data.to_csv(\"quantized_mobilevit_prediction_times.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3otSjsJ40dWh",
        "outputId": "ee19daa1-2071-4213-bb59-c1e6b82bbc42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (101859328 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (94487082 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3406: DecompressionBombWarning: Image size (96631920 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5mKuFgub1dg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}